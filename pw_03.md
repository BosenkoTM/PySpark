# Практическая работа №3. Построение сквозного ML-пайплайна на больших данных с помощью Spark MLlib

---

## Цель работы
Научиться строить полные конвейеры машинного обучения (ML Pipelines) на платформе Apache Spark. Студенты пройдут путь от загрузки «сырых» больших данных и конструирования признаков (Feature Engineering) до обучения модели, оценки её качества и интерпретации результатов для решения бизнес-задач компании (на примере фитнес-индустрии).

**Бизнес-кейс.** Вы — Data Scientist в компании HealthTech (аналог Endomondo/Strava). Ваша задача — разработать прогностические модели для улучшения удержания клиентов, персонализации предложений и автоматической классификации активности.

**Задачи:**
-  Настроить среду разработки (Spark + Jupyter).
-  Выполнить предобработку данных: очистка, работа со сложными типами (массивы, timestamps).
-  Реализовать **Feature Engineering**: преобразование категориальных признаков, векторизация, нормализация.
-  Построить и обучить модель машинного обучения с использованием библиотеки **Spark MLlib**.
-  Оценить качество модели техническими метриками (ROC-AUC, RMSE, Silhouette) и перевести их в бизнес-показатели.

---

## Необходимое ПО и данные
Работа выполняется на основе конфигурации **`ds_mgpu_Hadoop3+spark_3_4`** (или в Google Colab).

*   **Датасет:** `endomondoHR.json` (Данные о тренировках пользователей: пульс, скорость, высота, вид спорта, пол).
*   **Источник:** [Скачать данные](https://drive.google.com/file/d/1yiAp1fFDy3wSqUR0X_btCZPtuczbLwCe/view?usp=drive_link) или [зеркало](https://disk.yandex.ru/d/d80nsbNoP6F2vA).

**Инструкция по запуску (Локально/Docker):**
-  Клонировать репозиторий: `git clone https://github.com/BosenkoTM/PySpark.git`
-  Поместить `endomondoHR.json` в папку `data`.
-  Запустить контейнер: `sudo docker compose up`
-  Перейти в Jupyter Lab: `http://localhost:10000/lab`

---

## Методические указания. Структура ML-пайплайна

В работе необходимо использовать объектно-ориентированный подход библиотеки `pyspark.ml`.

### Шаг 1. Подготовка данных (Data Preparation)
Загрузка JSON, фильтрация `null` значений, преобразование типов.
```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, size

spark = SparkSession.builder.appName("EndomondoML").getOrCreate()
df = spark.read.json("data/endomondoHR.json")
# Пример фильтрации
df_clean = df.filter(size(col("heart_rate")) > 0).dropna(subset=["sport", "gender"])
```

### Шаг 2. Конструирование признаков (Feature Engineering)
Spark MLlib требует, чтобы входные данные были в формате векторов.
*   **StringIndexer / OneHotEncoder:** Для категориальных полей (`sport`, `gender`).
*   **SQLTransformer / UDF:** Для извлечения признаков из массивов (например, средний пульс, макс. высота).
*   **VectorAssembler:** Для объединения всех признаков в единый вектор `features`.

### Шаг 3. Обучение модели (Modeling)
Выбор алгоритма в зависимости от задачи (Классификация, Регрессия, Кластеризация).
```python
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml import Pipeline

rf = RandomForestClassifier(labelCol="label", featuresCol="features", numTrees=10)
pipeline = Pipeline(stages=[indexer, encoder, assembler, rf])
model = pipeline.fit(train_data)
```

### Шаг 4. Оценка и интерпретация (Evaluation)
Использование `BinaryClassificationEvaluator`, `RegressionEvaluator` или `ClusteringEvaluator`. Интерпретация важности признаков (`featureImportances`).

---

## Варианты индивидуальных заданий

В каждом варианте необходимо выполнить три задания, составляющих единый кейс.
*   **Задание 1 (Data & Features).** Подготовка датасета и создание специфических признаков.
*   **Задание 2 (Model Training).** Обучение указанной модели MLlib.
*   **Задание 3 (Business Metrics).** Оценка модели и бизнес-вывод.

**Вариант выбирается согласно номеру студента.**

| № | **Задание 1. Подготовка и Признаки (Feature Eng.)** | **Задание 2. Моделирование (MLlib)** | **Задание 3. Бизнес-интерпретация и Метрики** |
|---|---|---|---|
| 1 | Создать признаки: средний пульс, макс. высота. Целевая переменная: Пол пользователя (`gender`). | Задача **Классификации**. Модель: **Logistic Regression**. Предсказать пол по показателям тренировки. | Оценить **ROC-AUC**. Как точность определения пола помогает в таргетированной рекламе спортивных товаров? |
| 2 | Создать признаки: длительность тренировки, час начала. Целевая переменная: `sport` (отфильтровать только 'running' vs 'cycling'). | Задача **Бинарной классификации**. Модель: **Random Forest**. Отличить бег от велосипеда. | Оценить **Accuracy** и **Confusion Matrix**. Какие риски несет ошибка классификации для подсчета калорий? |
| 3 | Создать признаки: длина массива пульса (как прокси длительности), средняя скорость. Целевая: `gender`. | Задача **Классификации**. Модель: **Decision Tree**. | Визуализировать дерево (если возможно) или важность признаков. Какой признак важнее для определения пола: скорость или выносливость? |
| 4 | Создать признаки: средний пульс, дисперсия высоты. Целевая: `sport` (топ-3 популярных спорта). | Задача **Мультиклассовой классификации**. Модель: **Naive Bayes**. | Оценить **F1-Score**. Как автоматическое определение спорта улучшает UX приложения? |
| 5 | Создать признаки: `duration` (рассчитать), `avg_heart_rate`. Целевая: Прогноз сожженных калорий (сгенерировать синтетическую цель: `dur * avg_hr / 100`). | Задача **Регрессии**. Модель: **Linear Regression**. | Оценить **RMSE** и **R2**. Насколько надежна такая модель для медицинских рекомендаций? |
| 6 | Признаки: `avg_speed`, `max_altitude`, `min_altitude`. Фильтр: только 'bike'. | Задача **Кластеризации**. Модель: **K-Means**. Найти 3 кластера велотренировок. | Интерпретировать центры кластеров (например, "Горный велоспорт", "Шоссе", "Прогулка"). Как это использовать для рекомендаций маршрутов? |
| 7 | Признаки: `heart_rate` (весь массив, обрезанный до N первых значений или PCA). Целевая: `gender`. | Задача **Классификации**. Модель: **Gradient Boosted Trees (GBT)**. | Сравнить качество с Random Forest. Стоит ли прирост точности увеличения времени обучения в реальном продакшене? |
| 8 | Создать бинарную метку "Высокая интенсивность" (если средний пульс > 150). Признаки: скорость, высота. | Задача **Бинарной классификации**. Модель: **Support Vector Machine (LinearSVC)**. | Оценить **Precision** и **Recall**. Что важнее для приложения здоровья: не пропустить перегрузку (Recall) или не пугать зря (Precision)? |
| 9 | Признаки: время суток (утро/вечер), день недели, длительность. Целевая: `sport`. | Задача **Классификации**. Модель: **Random Forest**. Предсказать спорт по времени активности. | Анализ **Feature Importance**. Действительно ли "утро" коррелирует с бегом, а "вечер" с залом? Бизнес-вывод для push-уведомлений. |
| 10 | Признаки: `avg_speed`, `stddev_speed` (стабильность темпа). Целевая: `gender`. | Задача **Классификации**. Модель: **Logistic Regression** (с регуляризацией ElasticNet). | Интерпретация коэффициентов модели. Как стабильность темпа связана с полом пользователя? |
| 11 | Признаки: все доступные числовые метрики (пульс, скорость, высота). Данные: только 'running'. | Задача **Кластеризации**. Модель: **Bisecting K-Means** (k=4). | Сегментация бегунов: "Спринтеры", "Марафонцы", "Новички". Предложите маркетинговую стратегию для каждого сегмента. |
| 12 | Создать метку "Отток" (синтетическая: если кол-во тренировок пользователя < 5). Признаки: средняя длительность, пульс. | Задача **Классификации**. Модель: **Random Forest**. Прогноз оттока (Churn Prediction). | Как раннее выявление оттока влияет на LTV (Lifetime Value)? Расчет потенциально сохраненной выручки. |
| 13 | Признаки: массив высот (`altitude`) преобразовать в "набор высоты" (sum gain). Целевая: `duration`. | Задача **Регрессии**. Модель: **Decision Tree Regressor**. Прогноз времени по сложности рельефа. | Оценка **MAE** (средняя ошибка в минутах). Полезна ли эта модель для функции "расчет времени прибытия"? |
| 14 | Признаки: статистические показатели пульса (мин, макс, среднее, медиана). Целевая: `gender`. | Задача **Классификации**. Модель: **Multilayer Perceptron (Neural Network)**. | Сравнение нейросети с простыми моделями. Оправдано ли использование DL (Deep Learning) на таких данных? |
| 15 | Признаки: `avg_speed`, `avg_heart_rate`. Фильтр: 'running' и 'cycling'. | Задача **Кластеризации**. Модель: **Gaussian Mixture Model (GMM)**. | Анализ пересечения кластеров. Есть ли "пограничные" тренировки, которые сложно отличить? Как это влияет на авто-детект? |
| 16 | Признаки. Векторизация текстового описания (если есть) или OneHot для `sport`. Целевая: `gender`. | Задача **Классификации**. Модель: **Naive Bayes**. | Как использование вероятностной модели помогает в условиях неполных данных? |
| 17 | Создать признак `is_weekend` (выходной). Признаки: `duration`, `is_weekend`. Целевая: `avg_heart_rate` (прогноз интенсивности). | Задача **Регрессии**. Модель: **Generalized Linear Regression**. | Влияют ли выходные на интенсивность тренировок? Бизнес-вывод для планирования челленджей в приложении. |
| 18 | Признаки. Скалированные (StandardScaler) `duration` и `avg_speed`. Целевая: `sport` (top-5). | Задача **Классификации**. Модель: **OneVsRest (OVR)** с базовым классификатором LogisticRegression. | Оценка качества для каждого класса отдельно. Какие виды спорта модель путает чаще всего и почему? |
| 19 | Признаки. Гео-признаки (широта/долгота старта - округленные). Целевая: `sport`. | Задача **Классификации**. Модель: **Decision Tree**. Зависимость спорта от локации. | Анализ географии: "В парках бегают, в горах катаются". Как использовать это для гео-рекламы партнеров? |
| 20 | Признаки. Сложные агрегаты (скользящее среднее пульса - концептуально). Целевая: `gender`. | Построение **CrossValidator** (Grid Search) для подбора гиперпараметров любой модели. | Оценка влияния тюнинга гиперпараметров на метрику. Стоит ли затраченное вычислительное время улучшения на 1%? |

---

## Требования к отчетности

Работа сдается в виде ссылки на публичный репозиторий (GitHub/GitVerse/GitLab).

**Состав репозитория:**
-  **`README.md`**:
    *   Описание задачи, номер варианта.
    *   Инструкция по запуску (какой Docker образ, какие библиотеки).
    *   Ссылка на источник данных.
-  **`lab_03_ml.ipynb`**:
    *   Основной ноутбук с кодом.
    *   Код должен быть разбит на логические блоки (Setup -> ETL -> Features -> ML -> Eval).
    *   Обязательно использование `pyspark.ml.Pipeline`.
-  **`Report.md`**:
    *   **Введение:** Цель построения модели.
    *   **Предобработка:** Какие признаки созданы, как обработаны пропуски (с примерами кода/скриншотами).
    *   **Моделирование:** Параметры модели, процесс обучения.
    *   **Результаты:** Таблицы с метриками (Accuracy, RMSE и др.), графики (ROC Curve, Cluster Plot).
    *   **Бизнес-вывод:** Ответ на вопрос из Задания 3. Как эта модель принесет деньги или пользу компании?

---

## Критерии оценки

| Категория | Критерий | Баллы |
| :--- | :--- | :--- |
| **1. Техническая реализация (Spark Core & SQL)** | **3 баллов** | |
| | Данные корректно загружены, очищены от null/выбросов. | 1 |
| | Выполнена сложная обработка массивов/дат с помощью UDF или встроенных функций Spark. | 2 |
| **2. Машинное обучение (Spark MLlib)** | **4 баллов** | |
| | Корректно применены Feature Transformers (`VectorAssembler`, `StringIndexer`, `Scaler` и др.). | 1 |
| | Использован `Pipeline` API. Данные разделены на Train/Test. Модель обучена без ошибок. | 2 |
| | Произведена валидация модели на тестовой выборке с использованием соответствующих Evaluators. | 1 |
| **3. Аналитика и Бизнес-ценность** | **2 баллов** | |
| | Метрики качества интерпретированы корректно (не просто "Accuracy=0.8", а "Мы угадываем 8 из 10..."). | 1 |
| | Сделан обоснованный бизнес-вывод, связывающий работу модели с прибылью/эффективностью продукта. | 1 |
| **4. Оформление** | **1 балла** | |
| | Репозиторий и отчет оформлены согласно требованиям. Код чистый и документированный. | 1 |
| **Итого** | | **10** |

```

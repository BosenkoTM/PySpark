## Разведочный анализ данных с помощью PySpark
#### Цель и задачи работы:
- Познакомиться с понятием «большие данные» и способами их обработки;
- Познакомиться с инструментом `Apache Spark` и возможностями, которые он предоставляет для обработки больших данных.
- Получить навыки выполнения разведочного анализа данных использованием `pyspark`.

#### Порядок выполнения работы:
1. Запустите `Docker Desktop` и добейтесь его работоспособности или запустить [файл](advanced_pyspark_for_exploratory_data_analysis.ipynb)  в colab.
2. Клонировать текущий репозиторий на компьютер в случае работы локально в Docker:
> `$ git clone https://github.com/BosenkoTM/PySpark.git`
3. Скачайте датасет, расположенный по адресу `https://drive.google.com/file/d/1yiAp1fFDy3wSqUR0X_btCZPtuczbLwCe/view?usp=drive_link`. Распакуйте его и поместите файл `endomondoHR.json` в директорию `data` проекта (если директория отсутствует, создайте ее).
4. Запустите докер-контейнер со средой разработки и инструментом `Apache Spark` и дождитесь завершения его работы.
> `$ docker-compose up`
5. Откройте браузер и перейдите по адресу: http://localhost:10000/lab
6. Откройте в браузере файл ноутбука с примером разведочного анализа `advanced-pyspark-for-exploratory-data-analysis.ipynb`. Изучите этот файл и запустите его.
7. **Рассмотрите датасет для дальнейшего анализа согласно варианта**. 

**Обратите внимание:**
* Для сокращения расчетного времени можно обрабатывать только часть датасета;
* **Плагиатные работы не принимаются!**.

В датасете должны быть представлены табличные данные, желательный объем — от нескольких сотен мегабайт. Датасеты можно выбрать на следующих ресурсах:

[kaggle](https://www.kaggle.com/datasets) (для скачивания датасета требуется регистрация);

[UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).

8. Выполните разведочный анализ датасета с определением: 
* типов признаков в датасете; 
* пропущенных значений и их устранением; 
* выбросов и их устранением; 
* расчетом статистических показателей признаков (средних, квартилей и т.д.); 
* визуализацией распределения наиболее важных признаков; 
* корреляций между признаками.

9. Сделайте выводы по работе.
10. Сохраните ноутбук с проведенным анализом в `GitHub / GitLab`, в котором опишите постановку задачи, описание датасета со ссылкой на него, проведенный разведовательный анализ и выводы.

**К отчету** следует представить репозиторий на `GitHub / GitLab` с выполненным разведочным анализом, а также быть готовым продемонстрировать работоспособность кода и пояснить спорные моменты.

#### Список теоретических вопросов к отчету:
1. Фреймворк обработки больших данных `Apache Spark`, его назначение, функции и отличия от `Hadoop MapReduce`.
2. Понятие устойчивого распределенного набора данных (RDD). Понятие раздела RDD (partition). Способы создания RDD. Трансформации (transformations) и действия (actions). Кэширование (cache) данных в Spark.
3. RDD и PairRDD: понятие, назначение. Основные трансформации (transformations) и действия (actions) над ними.
4. Реализация концепции MapReduce в фреймворке Spark. Функции map, flatMap, mapValues, mapPartitions, reduce, reduceByKey.
5. Модели запуска Spark-приложений (YARN, Standalone, Kubernetes). Понятие драйвера (driver) и исполнителей (executors). Понятия задания (job), этапа (stage) и задачи (task). Модель ленивых вычислений (lazy) и ее применение в Spark. Понятие ориентированного ациклического графа (Directed Acyclic Graph, DAG).
6. Операция перемешивания данных (shuffle): причины возникновения, влияние на производительность. Класс Partitioner. Пути повышения производительности.
7. Понятие датафрейма в Spark. Основные операции над датафреймами. Скалярные функции, агрегирующие функции, оконные функции. Оптимизация запросов. Catalyst.
8. Клиентский (client) и кластерный (cluster) режимы работы Apache Spark.


| Вариант | Задание 1                                                                                                | Задание 2                                                                                                   | Задание 3                                                                                                                               |
| :------ | :------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- |
| 1       | Опишите структуру данных (схему), представленную в разделе 2. Какие типы данных показались вам необычными для бизнес-анализа и почему? | Интерпретируйте диаграммы (круговую и столбчатую) из раздела 5, показывающие топ-5 видов спорта. Какие выводы для бизнеса можно сделать?        | Объясните, почему обнаружение пропущенных значений и аномальных нулей (раздел 3) важно перед началом анализа. Какие риски несет их игнорирование? |
| 2       | Проанализируйте вывод команды `df.describe()` в разделе 2. Какие предварительные инсайты о пользователях и их активностях можно получить? | Интерпретируйте stacked bar chart "Список всех занятий в зависимости от пола" (раздел 6). В каких видах спорта наблюдается наибольший гендерный дисбаланс? | Зачем нужны UDF (User Defined Functions), описанные в разделе 7? Приведите пример бизнес-задачи, где может понадобиться создать новую метрику с помощью UDF. |
| 3       | На основе сводной таблицы в разделе 3 (`sum_dfs[0]`), сформулируйте 3 ключевых показателя (KPI), которые могли бы отслеживать менеджеры продукта Endomondo. | Изучите таблицу и диаграммы топ-5 видов спорта по *количеству тренировок* (раздел 6). Сравните с топ-5 по *количеству пользователей* (раздел 5). Есть ли различия и о чем они говорят? | Интерпретируйте гистограммы распределения количества рекордов за тренировку по видам спорта (раздел 5, конец). Для каких видов спорта характерны очень короткие/длинные сессии записей? |
| 4       | Объясните своими словами концепцию "Ленивой оценки" (Lazy Evaluation) в Spark (раздел 4). Почему это может быть важно для аналитика, работающего с большими данными, даже если он не пишет код? | Проанализируйте boxplot "Sports count by gender" (раздел 6). Что он говорит о распределении количества видов спорта, которыми занимаются мужчины и женщины? | Интерпретируйте гистограммы распределения продолжительности тренировок по видам спорта (раздел 7). Какие бизнес-гипотезы можно выдвинуть на основе этих данных (например, о пользовательских привычках)? |
| 5       | В разделе 3 было принято решение удалить тренировки с менее чем 50 записями. Оцените это решение с точки зрения бизнес-аналитика. Какие плюсы и минусы? | Изучите таблицу `interval_statistic_df` (раздел 8). Объясните значения для строк 'mean interval' и '50th percentile interval' для вида спорта 'running'. Что означают эти метрики? | Проанализируйте гистограммы распределения времени начала тренировки (раздел 8). Для каких видов спорта характерен бимодальный (утро/вечер) паттерн? Какие выводы можно сделать о стиле жизни пользователей? |
| 6       | Какие столбцы в исходных данных являются массивами (согласно разделу 2)? Приведите пример бизнес-вопроса, для ответа на который потребуется анализ данных внутри одного из этих массивов. | Интерпретируйте диаграмму `interval_statistic_df` (раздел 8). Почему для 'max interval' и 'stdev interval' используется отдельная правая ось Y? Что это говорит о данных? | Опишите цель процесса сэмплирования данных, показанного в разделе 8 (`sampling_data`). В каких ситуациях бизнес-аналитику может потребоваться работать с выборкой, а не со всем набором данных? |
| 7       | Проанализируйте таблицу `gender_user_activity_count` (раздел 3). Рассчитайте среднее количество тренировок на одного пользователя для каждого пола. Что это говорит о вовлеченности? | Сравните столбцы '25th percentile interval' и '75th percentile interval' для 'cycling' и 'walking' в таблице `interval_statistic_df` (раздел 8). Что можно сказать о стабильности записи данных для этих активностей? | Интерпретируйте графики необработанного пульса по нормированному времени для 'running' и 'swimming' (раздел 8). Какие различия в динамике пульса вы видите? Какие факторы могут на это влиять? |
| 8       | В разделе 7 были созданы новые столбцы (`date_time`, `workout_start_time`, `duration`, `interval`) с помощью UDF. Какие новые бизнес-вопросы стало возможно исследовать благодаря этим столбцам? Приведите 2 примера. | Объясните, что показывает метрика '95th percentile interval' в таблице `interval_statistic_df` (раздел 8). Почему она может быть более информативной, чем 'max interval' при анализе типичного поведения? | Изучите 3D-графики траекторий тренировок (раздел 8). Какую ценность для бизнеса (например, для разработки фич приложения) может нести анализ таких траекторий? |
| 9       | На основе информации из раздела 3, оцените полноту данных по полу (`gender`). Как проблема с 'unknown' гендером может повлиять на выводы анализа? Предложите варианты решения. | Интерпретируйте вывод `user_more_sports_df.describe()` (раздел 6). Что можно сказать о среднем и максимальном количестве видов спорта, которыми увлекаются пользователи из этой группы? | Для чего рассчитывался столбец `normalized_date_time` в разделе 8 перед построением графиков пульса? Какую проблему это решает при сравнении разных тренировок? |
| 10      | Представьте, что вы должны подготовить отчет для маркетингового отдела. Какие 3 ключевых вывода из всей практической работы вы бы включили в первую очередь и почему? | Изучите код и результат создания `highest_sport_users_df_renamed` (раздел 5), где добавлена категория 'others'. Почему важно учитывать категорию 'others' при анализе и визуализации? | Проанализируйте 3D-графики тренировок (раздел 8). Какие из представленных видов спорта, судя по графикам, включают значительные изменения высоты (`altitude`)? |
| 11      | Опишите данные, которые содержатся в столбцах `latitude`, `longitude`, `altitude`. Для каких бизнес-задач (кроме визуализации маршрута) эти данные могут быть полезны? | Проанализируйте распределение 'workout_start_time' для 'hiking' (раздел 8). Чем оно отличается от распределения для 'running'? Какие гипотезы это может породить? | Что означает столбец `PerWorkoutRecordCount` (раздел 3)? Как его можно использовать для оценки качества или характера тренировки? |
| 12      | Какие виды спорта, согласно анализу в разделах 5 и 6, являются самыми популярными и по числу пользователей, и по числу тренировок? Есть ли виды спорта, популярные в одной метрике, но не в другой? | Интерпретируйте статистику по `duration` (раздел 7, `df.select('duration').toPandas().describe().T`). Какова медианная продолжительность тренировки? Что означает большая разница между 75-м перцентилем и максимумом? | Объясните бизнес-ценность анализа интервалов записи данных (`interval`, раздел 8). Почему компании Endomondo может быть важно знать, как часто их трекеры записывают данные? |
| 13      | Как вы думаете, почему в данных присутствует пол 'unknown' (раздел 3)? Предложите 2-3 возможные причины. | Сравните гистограммы `PerWorkoutRecordCount` для 'running' и 'indoor cycling' (раздел 5). Какие выводы можно сделать о типичной плотности записи данных для этих активностей? | Представьте, что Endomondo хочет запустить таргетированную кампанию для пользователей, занимающихся несколькими видами спорта. Какие данные из анализа в разделе 6 помогут сегментировать этих пользователей? |
| 14      | Изучите раздел 7, где создается столбец `duration`. Какие виды спорта, судя по гистограммам, имеют наибольшую среднюю продолжительность тренировок? Подтверждается ли это таблицей `describe()`? | В разделе 8 используется `combineByKey` для расчета статистики по интервалам. Объясните (без деталей кода), какую задачу решает этот шаг агрегации данных. | Какие потенциальные проблемы с качеством данных можно выявить, анализируя графики необработанного пульса (раздел 8)? (например, аномальные пики, пропуски) |
| 15      | Опишите своими словами разницу между RDD и DataFrame в Spark (упоминается в разделе 8). Почему для некоторых задач может быть удобнее использовать RDD? | Проанализируйте диаграмму `interval_statistic_df` (раздел 8). Для каких видов спорта характерен наибольший разброс значений интервалов (высокий `stdev interval`)? Что это может означать? | Предложите 2-3 бизнес-идеи (новые фичи, маркетинговые акции), основанные на анализе времени начала тренировок (`workout_start_time`, раздел 8). |
| 16      | Какие основные библиотеки Python (кроме PySpark) используются в этой практической работе? Какова их роль в анализе данных? | Интерпретируйте результаты анализа пользователей, занимающихся более чем одним видом спорта (`user_more_sports_df`, раздел 6). Какой процент пользователей занимается более чем одним видом спорта (оценочно)? | Для анализа пульса (раздел 8) данные были сэмплированы. Какие ограничения на выводы накладывает использование выборки? |
| 17      | Что означает параметр `mode="DROPMALFORMED"` при чтении JSON файла в разделе 1? Какие риски это несет для анализа данных? | Сравните распределение 'workout_start_time' для мужчин и женщин в рамках одного популярного вида спорта (например, 'running') по гистограммам из раздела 8. Есть ли заметные отличия? | Какие еще данные (которых нет в этом датасете) могли бы быть полезны для более глубокого анализа поведения пользователей Endomondo? Приведите 2-3 примера. |
| 18      | Опишите шаги, предпринятые в разделе 3 для первичной оценки данных (`user_activity_workout_summarize`). Почему важно получить эти общие цифры перед углубленным анализом? | Проанализируйте stacked bar chart гендерного распределения по видам спорта (раздел 6). Назовите 2-3 вида спорта с наиболее сбалансированным гендерным составом. | Интерпретируйте 3D-график для 'orienteering' (раздел 8). Что необычного в траектории этого вида спорта по сравнению, например, с 'running'? |
| 19      | Какая информация теряется при агрегации данных о времени тренировки до часа начала (`workout_start_time = hour(...)` в разделе 7)? В каких случаях эта потеря информации может быть критичной? | Изучите таблицу `top_activities_by_gender_df` (раздел 6). Какой вид спорта из топ-5 имеет наибольшую долю 'unknown' гендера? Какие проблемы это создает? | Объясните, как анализ данных о частоте пульса (`heart_rate`) может быть использован для персонализации пользовательского опыта в фитнес-приложении. |
| 20      | В разделе 1 упоминается сравнение производительности Spark и Pandas. В каких ситуациях, исходя из этого сравнения, использование Spark является предпочтительным для бизнес-аналитика? | Проанализируйте гистограммы `duration` для 'aerobics' и 'strength training' (раздел 7). Сравните их типичную продолжительность. | На основе 3D-графиков (раздел 8), можно ли предположить, какие тренировки проходили в городской среде, а какие - на природе? По каким признакам? |
| 21      | Просмотрите код UDF `get_interval` (раздел 7). Что возвращает эта функция, если в тренировке была всего одна временная метка? Как это может повлиять на дальнейший анализ? | Интерпретируйте boxplot `Sports count by gender` (раздел 6). Что означают точки над "усами" диаграммы? Какую информацию они несут? | Предложите метрику для оценки "интенсивности" тренировки, которую можно было бы рассчитать на основе имеющихся данных (например, используя `heart_rate` и `duration`). |
| 22      | Какие виды визуализации использовались в практической работе? Для каких типов данных или задач каждый вид визуализации подходит лучше всего? | Проанализируйте таблицу `interval_statistic_df` (раздел 8). Найдите вид спорта с минимальным средним интервалом (`mean interval`). Что это говорит о записи данных для этого спорта? | Как можно использовать данные о `longitude` и `latitude` для выявления популярных мест для тренировок в определенном городе (если бы были данные по одному городу)? |
| 23      | Оцените названия столбцов в исходном датасете (раздел 2). Насколько они понятны для бизнес-пользователя? Есть ли столбцы, требующие переименования или дополнительного описания? | В разделе 6 рассчитывается процент пользователей, занимающихся более чем 1 видом спорта. Как бы вы интерпретировали этот показатель для бизнеса? Это высокий или низкий процент? | Если бы у вас были данные о погоде во время тренировки, как бы вы могли их использовать совместно с данными о `duration` или `heart_rate`? |
| 24      | Зачем в разделе 7 при конвертации времени из Unix timestamp вычиталось 7 часов (`timedelta(hours=7)`)? Почему важно учитывать часовые пояса при анализе временных данных? | Сравните `mean interval` и `50th percentile interval` (медиану) в таблице `interval_statistic_df` (раздел 8). Для каких видов спорта эти значения сильно различаются? Что это говорит о распределении интервалов? | Представьте, что бизнес хочет понять, как часто пользователи бросают тренировку на полпути. Какие из имеющихся данных могли бы косвенно указывать на это? |
| 25      | В разделе 1 код инициализирует SparkSession с определенными параметрами (`MAX_MEMORY`, `timeout`). Почему настройка этих параметров важна при работе с большими данными? | Проанализируйте график распределения `PerWorkoutRecordCount` (раздел 5). Видны ли пики на определенных значениях (например, 500)? Что это может означать? | Какие этические соображения должен учитывать бизнес-аналитик при работе с данными о местоположении (`latitude`, `longitude`) и биометрии (`heart_rate`) пользователей? |
| 26      | Опишите процесс создания категориальной переменной 'others' при анализе топ-5 видов спорта (раздел 5). Зачем это делается и как влияет на интерпретацию диаграмм? | Изучите гистограммы `workout_start_time` (раздел 8). Есть ли виды спорта, которые чаще практикуют в рабочее время (например, с 9 до 17)? | Как можно использовать данные о `speed` (хотя детально не анализировались) в сочетании с `heart_rate` для оценки эффективности тренировки? |
| 27      | Какой столбец используется для уникальной идентификации каждой тренировки? А какой для уникальной идентификации пользователя? (Раздел 2) | В разделе 8 при построении графика `interval_statistic_df` используются одновременно bar chart и line chart. Объясните, почему выбрано такое сочетание для визуализации разных статистик. | Предложите способ визуализации данных о маршруте тренировки в 2D (используя только `longitude` и `latitude`), который мог бы быть альтернативой 3D-графику. |
| 28      | Как наличие столбца `url` (раздел 2) могло бы обогатить анализ, если бы данные по этим ссылкам были доступны? | Интерпретируйте значение 'stdev interval' для 'mountaineering' в таблице `interval_statistic_df` (раздел 8). Что означает высокое стандартное отклонение в данном контексте? | Если бы вы обнаружили, что у значительной части пользователей очень высокие или низкие значения `heart_rate` во время отдыха (начало/конец тренировки), какие выводы или дальнейшие шаги вы бы предложили? |
| 29      | В разделе 5 строится круговая диаграмма с параметром `explode`. Что делает этот параметр и зачем он используется при визуализации? | Проанализируйте гистограммы `duration` (раздел 7). Для каких видов спорта распределение сильно смещено вправо (есть "длинный хвост" очень долгих тренировок)? | Как можно было бы использовать данные `altitude` для классификации тренировок (например, "равнинная", "холмистая", "горная")? |
| 30      | Практическая работа использует Google Colab и загружает данные из Google Drive / Yandex Disk. Какие преимущества и недостатки у такого подхода для бизнес-аналитика по сравнению с работой в корпоративной BI-системе? | Изучите код `sampling_data` (раздел 8). Как обеспечивается случайность выборки пользователей и тренировок? Почему это важно для репрезентативности выборки? | Предложите бизнес-метрику, которая бы отражала "регулярность" занятий спортом конкретным пользователем, используя столбец `timestamp` или `date_time`. |

#### Литература для подготовки к отчету:
1. Изучаем Spark: молниеносный анализ данных / Х. Карау, Э. Конвински, П. Венделл, М.М. Захария // ДМК Пресс, 2015. — 304 с.: ил.
2. Data Exploration // Learning Apache Spark with Python [Электронный  ресурс] / W. Feng. - [2021]. - Режим доступа : https://runawayhorse001.github.io/LearningApacheSpark/exploration.html (дата обращ. 10.03.2024).
3. Advanced Pyspark for Exploratory Data Analysis [Электронный  ресурс]. – [2022]. – Режим доступа : https://www.kaggle.com/code/tientd95/advanced-pyspark-for-exploratory-data-analysis (дата обращ. 10.03.2024). 
4. Exploratory Data Analysis (EDA) with PySpark on Databricks [Электронный  ресурс]. – [2020]. – Режим доступа : https://towardsdatascience.com/exploratory-data-analysis-eda-with-pyspark-on-databricks-e8d6529626b1 (дата обращ. 10.03.2024).
5. Exploratory data analysis with pySpark [Электронный  ресурс]. – [2020]. – Режим доступа : https://github.com/BosenkoTM/PySpark/tree/main/pySpark_tutorial-master (дата обращ. 10.03.2024).
6. Официальный сайт Apache Spark [Электронный  ресурс]. – [2022]. – Режим доступа : https://spark.apache.org/ (дата обращ. 10.03.2024).
7. Уайт, Т. Hadoop: Подробное руководство / Т. Уайт. — 3-е изд. — СПб. : Питер, 2013. — 672 с.: ил.
